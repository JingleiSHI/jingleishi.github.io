<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Jinglei Shi's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Jinglei Shi is currently a lecturer in Computer Science School of Nankai University (NKU).">
  <meta name="keywords" content="Jinglei Shi, 时晶磊, shijinglei, Jinglei, Shi, Deep Learning, INRIA, Computer, Vision">
  <meta name="author" content="Jinglei Shi" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {

      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();

        // Store hash
        var hash = this.hash;

        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){

          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>Jinglei</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#publications" class="w3-bar-item w3-button">Research</a>
    <a href="#service" class="w3-bar-item w3-button">Services</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">Jinglei</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 200px" alt="profile photo" src="images/Jinglei.png">
      <h1>Jinglei Shi (时晶磊)</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am currently a lecturer in <a href="https://cc.nankai.edu.cn/">Computer Science School of Nankai University (NKU)</a>, before that, 
		I worked a post-doctoral research fellow at <a href="https://www.inria.fr/fr">French Institute for Research in Computer Science and Automation (INRIA)</a>, France from 2020-2021.
		And I received my PhD degree in Computer Science at INRIA, under the supervision of Prof. <a href="https://people.rennes.inria.fr/Christine.Guillemot/">Christine Guillemot</a></a> and A/Prof. <a href="https://scholar.google.com/citations?user=zvdY0EcAAAAJ&hl=zh-CN">Xiaoran Jiang</a></a>. 
		I got my Bachelor's degree in Electronic Information Engineering from <a href="https://www.uestc.edu.cn/">UESTC</a> 
		and Master's degree & Engineer's degree in Image Processing from <a href="https://www.imt-atlantique.fr/fr">IMT Atlantique</a>. My research focuses on deep learning, computational photography, and 3D vision, etc.
        </p>
        <p class="w3-center">
          <a href="mailto:jinglei.shi@nankai.edu.cn">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=9tYW9LcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/jinglei-shi-923708a0/"> LinkedIn </a> &nbsp/&nbsp
		  <a href="data/CV_English.pdf"> CV </a> 
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> 03/2025, three papers have been accepted by CVPR 2025</a>.</li></p>	  
      <p><li> 12/2024, one paper has been accepted by NeurIPS 2024</a>.</li></p>
      <p><li> 09/2024, one paper has been accepted by ECCV 2024</a>.</li></p>
      <p><li> 07/2024, one paper has been accepted by Trans. Image Process.</a>.</li></p>
      <p><li> 07/2024, one paper has been accepted by ICME 2024</a>.</li></p>
      <p><li> 06/2024, one paper has been accepted by CVPR 2024</a>.</li></p>
      <p><li> 06/2023, one paper has been accepted by CVPR 2023</a>.</li></p>
      <p><li> 02/2023, one paper has been accepted by ICASSP 2023</a>.</li></p>
      <p><li> 12/2022, one paper has been accepted by Trans. Image Process.</a>.</li></p>
      <p><li> 09/2022, I joined Nankai University.</li></p>
      <p><li> 03/2022, one paper has been accepted by Trans. Comput. Imaging</a>.</li></p>
      <p><li> 02/2022, one paper has been accepted by VISAPP 2022</a>.</li></p>
      <p><li> 10/2021, one paper has been accepted by Neurocomputing</a>.</li></p>
      <p><li> 06/2021, I received my PhD degree in Computer Science.</li></p>
      <p><li> 06/2020, one paper has been accepted by CVPR 2020</a>.</li></p>
      <p><li> 06/2019, one paper has been accepted by Trans. Image Process.</a>.</li></p>
      <p><li> 05/2019, one paper has been accepted by ICASSP 2019</a>.</li></p>
  </div>
  
 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Research</h2>
      <p class="w3-left-align" style="line-height:200%">
        * Equal Contribution, # Corresponding Author
      </p>

	<font face="helvetica, ariel, 'sans serif'">
		<table border="0" cellpadding="20" cellspacing="3" >			
			<tr>
				<td>
					<img height=160 width=320 src="images/nips2024.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>To Err Like Human: Affective Bias-Inspired Measures for Visual Emotion Recognition Evaluation</strong> <br>
					Chenxi Zhao, <strong>Jinglei Shi#</strong>, Liqiang Nie and Jufeng Yang <br>
					In <em>Advances in Neural Information Processing Systems</em> (<strong>NeurIPS 2024, CCF-A</strong>). <br>
					[<a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/f2bb120e9a2cb9c2a50921b7f865c421-Paper-Conference.pdf">Paper</a>]
					[<a href="https://github.com/ZhaoChenxi-nku/ECC">Github</a>]
				</td>
			</tr>
			
			<tr>
				<td>
					<img height=160 width=320 src="images/eccv2024.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>Seeing the Unseen: A Frequency Prompt Guided Transformer for Image Restoration</strong> <br>
					Shihao Zhou, Jinshan Pan, <strong>Jinglei Shi#</strong>, Duosheng Chen, Lishen Qu and Jufeng Yang <br>
					In <em>European Conference on Computer Vision</em> (<strong>ECCV 2024, CCF-B</strong>). <br>
					[<a href="https://link.springer.com/chapter/10.1007/978-3-031-72640-8_14">Paper</a>]
					[<a href="https://github.com/joshyZhou/FPro">Github</a>]
				</td>
			</tr>
			
			<tr>
				<td>
					<img height=160 width=320 src="images/tip2024.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>Learning Kernel-Modulated Neural Representation for Efficient Light Field Compression</strong> <br>
					<strong>Jinglei Shi#</strong>, Yihong Xu and Christine Guillemot <br>
					In <em>IEEE Transactions on Image Processing</em> (<strong>TIP 2024, CCF-A</strong>). <br>
					[<a href="https://ieeexplore.ieee.org/document/10579762">Paper</a>]
				</td>
			</tr>
			
			<tr>
				<td>
					<img height=160 width=320 src="images/icme2024.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>ICFRNet: Image Complexity Prior Guided Feature Refinement for Real-Time Semantic Segmentation</strong> <br>
					Xin Zhang, Teodor Boyadzhiev, <strong>Jinglei Shi#</strong> and Jufeng Yang <br>
					In <em>IEEE International Conference on Multimedia and Expo</em> (<strong>ICME 2024, CCF-B</strong>). <br>
					[<a href="https://ieeexplore.ieee.org/abstract/document/10687732/">Paper</a>]
				</td>
			</tr>
			
			<tr>
				<td>
					<img height=160 width=320 src="images/cvpr2024.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>Adapt or Perish: Adaptive Sparse Transformer with Attentive Feature Refinement for Image Restoration</strong> <br>
					Shihao Zhou, Duosheng Chen, Jinshan Pan, <strong>Jinglei Shi#</strong> and Jufeng Yang <br>
					In <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR 2024, CCF-A</strong>). <br>
					[<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Adapt_or_Perish_Adaptive_Sparse_Transformer_with_Attentive_Feature_Refinement_CVPR_2024_paper.html">Paper</a>]
					[<a href="https://github.com/joshyZhou/AST">Github</a>]
				</td>
			</tr>
			
			<tr>
				<td>
					<img height=160 width=320 src="images/cvpr2023.gif" loop=infinite border="3">
				</td>
				<td align="left"><strong>JAWS: Just A Wild Shot for Cinematic Transfer in Neural Radiance Fields</strong> <br>
					Xi Wang*, Robin Courant*, <strong>Jinglei Shi#</strong>, Eric Marchand and Marc Christie <br>
					In <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR 2023, CCF-A</strong>). <br>
				        [<a href="https://www.lix.polytechnique.fr/vista/projects/2023_cvpr_wang/">Website</a>]
					[<a href="https://arxiv.org/abs/2303.15427">Paper</a>]
					[<a href="https://www.youtube.com/watch?v=d0XtVqa5bdY&ab_channel=XiWang">Video</a>]
					[<a href="https://github.com/robincourant/jaws">Github</a>]
				</td>
			</tr>
								  
			<tr>
				<td>
					<img height=180 width=320 src="images/tpami2022.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>Light Field Compression via Compact Neural Scene Representation</strong> <br>
					<strong>Jinglei Shi</strong>, Christine Guillemot <br>
					In <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em> (<strong>ICASSP 2023, CCF-B</strong>). <br>
					[<a href="https://hal.science/hal-04017645/">Paper</a>]
				</td>
			</tr>
				
			<tr>
				<td>
					<img height=180 width=320 src="images/tip2021.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>Untrained Neural Network Prior for Compact Light Field Representation and Compression</strong> <br>
					Xiaoran Jiang, <strong>Jinglei Shi</strong>, Christine Guillemot <br>
					In <em>IEEE Transactions on Image Processing</em> (<strong>TIP 2022, CCF-A</strong>). <br>
					[<a href="https://ieeexplore.ieee.org/abstract/document/9934016">Paper</a>]
				</td>
			</tr>
			
			<tr>
				<td>
					<img height=160 width=320 src="images/spic2021.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>Axial Refocusing Precision Model with Light Fields</strong> <br>
					Zhaolin Xiao, <strong>Jinglei Shi</strong>, Xiaoran Jiang, Christine Guillemot <br>
					In <em>Signal Processing: Image Communication</em> (<strong>SPIC 2021, CCF-C</strong>). <br>
				</td>
			</tr>
		
			<tr>
				<td>
					<img width=320 src="images/tci2022.gif" loop=infinite border="3">
				</td>
				<td align="left"><strong>Deep Residual Architecture using Pixel and Feature Cues for View Synthesis and Temporal Interpolation</strong> <br>
					<strong>Jinglei Shi</strong>, Xiaoran Jiang, Christine Guillemot <br>
					In <em>IEEE Transactions on Computational Imaging</em> (<strong>TCI 2022</strong>). <br>
					[<a href="http://clim.inria.fr/research/TCI-VS-VI/index.html">Website</a>]
				</td>
			</tr>
		
			<tr>
				<td>
					<img width=320 src="images/visapp2022.gif" loop=infinite border="3">
				</td>
				<td align="left"><strong>Deep Video Frame Rate Up-Conversion Network using Feature-Based Progressive Residue Refinement</strong> <br>
					<strong>Jinglei Shi</strong>, Xiaoran Jiang, Christine Guillemot <br>
					In <em>International Conference on Computer Vision Theory and Applications</em> (<strong>VISAPP 2022 (Oral)</strong>). <br>
					[<a href="data/VISAPP2022.pdf">Paper</a>]
					[<a href="data/VISAPP.mp4">Video</a>]
					[<a href="http://clim.inria.fr/research/VISAPP2022/index.html">Website</a>]
				</td>
			</tr>
		
			<tr>
				<td>
					<img height=200 width=320 src="images/nc2021.png" loop=infinite border="3">
				</td>
				<td align="left"><strong>Axial Light Field Resolution Enhancement using a Learning-Based View Extrapolation Method</strong> <br>
					Zhaolin Xiao, <strong>Jinglei Shi</strong>, Xiaoran Jiang, Christine Guillemot <br>
					In <em>Neurocomputing</em> (<strong>NC 2021, CCF-C</strong>). <br>
					[<a href="data/NC2021.pdf">Paper</a>]
				</td>
			</tr>
		
			<tr>
				<td>
					<img width=320 src="images/cvpr2020.gif" loop=infinite border="3">
				</td>
				<td align="left"><strong>Learning Fused Pixel and Feature-Based View Reconstructions for Light Fields</strong> <br>
					<strong>Jinglei Shi*</strong>, Xiaoran Jiang*, Christine Guillemot <br>
					In <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR 2020 (Oral), CCF-A</strong>). <br>
					[<a href="data/CVPR2020.pdf">Paper</a>]
					[<a href="https://www.youtube.com/watch?v=JFLDYnPRl04">Video</a>]
					[<a href="https://github.com/JingleiSHI/FPFR">Github</a>]
				</td>
			</tr>
		
			<tr>
				<td>
					<img width=320 src="images/tip2019.gif" loop=infinite border="3">
				</td>
				<td align="left"><strong>A Framework for Learning Depth From a Flexible Subset of Dense and Sparse Light Field Views</strong> <br>
					<strong>Jinglei Shi</strong>, Xiaoran Jiang, Christine Guillemot <br>
					In <em>IEEE Transactions on Image Processing</em> (<strong>TIP 2019, CCF-A</strong>). <br>
					[<a href="data/TIP2019.pdf">Paper</a>]
					[<a href="http://clim.inria.fr/research/FlexDepthEstim/index.html">Website</a>]
				</td>
			</tr>
			
			<tr>
				<td>
					<img width=320 src="images/icassp2019.gif" loop=infinite border="3">
				</td>
				<td align="left"><strong>A Learning Based Depth Estimation Framework for 4D Densely and Sparsely Sampled Light Fields </strong> <br>
					Xiaoran Jiang, <strong>Jinglei Shi</strong>, Christine Guillemot <br>
					In <em>IEEE International Conference on Acoustics, Speech, and Signal Processing</em> (<strong>ICASSP 2019, CCF-B</strong>). <br>
					[<a href="data/ICASSP2019.pdf">Paper</a>]
					[<a href="http://clim.inria.fr/research/DepthEstim2/index.html">Website</a>]
					[<a href="data/ICASSP2019_poster.pdf">Poster</a>]
				</td>
			</tr>
		


		</table>
	</font>
  </div>

<!-- The Services Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE TPAMI</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE TIP</a> </p>
	  <p><li> Conference Reviewers of ICME Workshop, Eurographics</p>
      <p><li> Invited talk for <a href="http://clim.inria.fr/workshop2.html">workshop on Computational Imaging</a>
	  <p><li> Contributor to ERC advanced grant <a href="https://erc.easme-web.eu/?p=694122">CLIM Project</a>, PI: Prof. Christine Guillemot
	  <p><li> Contributor to French National Research Agency <a href="https://anr.fr/Project-ANR-19-CHIA-0007">DeepCIM Project</a>, PI: Prof. Christine Guillemot
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> 2014, China Scholarship Council Scholarships</p>
    <p><li> 2012, 2013, The Top-Class People's Scholarship, UESTC</p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">
  <!-- Default Statcounter code for Jinglei Shi's Homepage
  http://jingleishi.github.io -->
  No.
  <script type="text/javascript">
  var sc_project=12708301; 
  var sc_invisible=0; 
  var sc_security="3d1b6e01"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since Feb 2022. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript><div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12708301/0/3d1b6e01/1/"
  alt="web stats"
  referrerPolicy="no-referrer-when-downgrade"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->
  </div>

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
